{
  "hash": "c389f5e1a880e9ea503f38694f2a3b30",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"An introduction to species distribution modelling using {tidysdm} & {tidymodels}\"\ndescription: |\n  Species distribution modelling is a common task for ecologists in R. Here we show the fundamental steps to build, assess and use models to predict species distributions using {tidymodels} & {tidysdm}, modern packages that use tidy syntax to run and plot geospatial models.\nauthor:\n  - name: \"Dax Kellie\"\n  - name: \"Shandiya Balasubramaniam\"\ndate: \"2024-04-30\"\ntitle-block-banner: \"#B8573E\"\ntoc: true\ntoc-location: left\ntoc-depth: 2\ncategories:\n  - Eukaryota\n  - Animalia\n  - Aves\n  - Summaries\n  - Maps\nimage: sdm-map.png\nfreeze: true\ndraft: false\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n<!-- remove metadata section -->\n\n\n```{=html}\n<style>\n  #title-block-header.quarto-title-block.default .quarto-title-meta {\n      display: none;\n  }\n</style>\n```\n\n<!-- Author card -->\n\n::: author-card\n::: author-card-text\n#### Author\n\n[Dax Kellie](https://labs.ala.org.au/about/Kellie_Dax/)\\\n[Shandiya Balasubramaniam](https://labs.ala.org.au/about/Balasubramaniam_Shandiya/)\n\n#### Date\n\n30 April 2024\n:::\n\n::: author-card-image\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://raw.githubusercontent.com/AtlasOfLivingAustralia/ala-labs/main/images/people/dax.jpg){width=120px style=\"clip-path: circle();\"}\n:::\n:::\n\n:::\n\n::: author-card-image\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://raw.githubusercontent.com/AtlasOfLivingAustralia/ala-labs/main/images/people/shandiya.png){width=120px style=\"clip-path: circle();\"}\n:::\n:::\n\n:::\n:::\n\n<!------------------------ Post starts here ------------------------>\n\nSpecies distribution models (SDMs) offer a way to quantify relationships between biodiversity observations and environmental variables, and are widely used in biogeography, conservation biology, and macroecology. SDMs allow us to assess how suitable an area is for a species, which has implications for predicting range shifts of invasive or threatened species, and understanding habitat suitability under different climate change scenarios.\n\nThe process of fitting and choosing the best model is iterative and, often, different modelling approaches are used to make multiple predictions that can be averaged to get a final result. Here, we walk through the steps of building a SDM for the laughing kookaburra in a small area of New South Wales, Australia, using [tidymodels](https://www.tidymodels.org/) and [tidysdm](https://evolecolgroup.github.io/tidysdm/). tidymodels is a collection of packages for modelling using [tidyverse principles](https://tidyverse.tidyverse.org/articles/manifesto.html), and tidysdm implements SDMs using the tidymodels framework.\n\n\n::: {.callout-note collapse=\"true\"}\n## Pros & cons of tidymodels\n\n:::{layout-ncol=\"2\"}\n\n#### Pros\n\n-   **Machine learning models are easier to build and use** <br>\n[Tidymodels packages are good for machine learning models in R. Many types of SDMs like MaxEnt models are well-suited for tidymodels.]{style=\"font-size:.7rem;\"}\n-   **Data transformations are more transparent** <br>\n[Steps like log-transformations, scaling and centring are occur *within* the model building workflow (rather than before during data wrangling), making these data manipulations more transparent to the model's results.]{style=\"font-size:.7rem;\"}\n-   **Functions are modular** <br>\n[Tidymodels functions are modular, so many different types of models can be run with the same functions and workflow.]{style=\"font-size:.7rem;\"}\n-   **Many different models can be one at once** <br>\n[Many different types of models can be run at once using a `workflow_set()`. These different models can also be compared and even combined into a final predictive model.]{style=\"font-size:.7rem;\"}\n-   **Auto-detects visualisations** <br>\n[Helper functions like `autoplot()` make visualising model performance less cumbersome by determining which visual to display based on the previous object's output.]{style=\"font-size:.7rem;\"}\n-   **Make something pretty good quickly** <br>\n[Users can build fairly good predictive models quite quickly, streamlining the process of going from raw data to prediction.]{style=\"font-size:.7rem;\"}\n\n#### Cons\n\n-   **Learning the workflow can be hard** <br> \n[Learning tidymodels can be confusing and time consuming because the workflow differs quite a lot from other popular statistical modelling packages in R.]{style=\"font-size:.7rem;\"}\n-   **Confusing function names** <br>\n[The {recipes} package uses function names like `prep()`, `bake()` and `juice()` which makes them difficult to know what they do or when to use them.]{style=\"font-size:.7rem;\"}\n-   **Learning function outputs takes time** <br> \n[Learning what output to expect from each function, and what helper functions are available for each step takes time.]{style=\"font-size:.7rem;\"}\n-   **Tidymodels isn't good at everything** <br>\n[Tidymodels is optimised for machine learning, but it isn't necessarily \"better\" than other packages like {dismo}, {lme4}, {biomod2}, or packages for bayesian models like {tidybayes} or {brms}.]{style=\"font-size:.7rem;\"}\n\n:::\n\n:::\n\nTo begin, we can load some packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(galah)\nlibrary(tidyverse)\nlibrary(tidymodels) \nlibrary(tidysdm) # devtools::install_github(\"EvolEcolGroup/tidysdm\")\nlibrary(terra)\nlibrary(tidyterra)\nlibrary(here)\nlibrary(sf)\nlibrary(ozmaps)\n```\n:::\n\n\n## Download data\n\n### Download biological data\n\nOur model will use occurrence data of laughing kookaburras (*Dacelo novaeguineae*) in a small area in New South Wales. The laughing kookaburra is the largest Kingfisher in the world.\n\n::: {layout-ncol=\"3\" style=\"margin-left: auto; margin-right: auto;\"}\n<img src=\"https://ala-images.s3.ap-southeast-2.amazonaws.com/store/7/5/e/4/8987a472-fcbf-4ae5-be44-e5dc50eb4e57/original\" class=\"rounded\"/></img>\n\n<img src=\"https://ala-images.s3.ap-southeast-2.amazonaws.com/store/3/c/6/0/27780a83-c4b3-4f44-ade3-2f401ac006c3/original\" class=\"rounded\"/></img>\n\n<img src=\"https://ala-images.s3.ap-southeast-2.amazonaws.com/store/2/5/0/0/5c796423-708e-4e1c-adf6-72131ac40052/original\" class=\"rounded\"/></img>\n:::\n\n::: figure-caption\nLeft: [*Dacelo (Dacelo) novaeguineae* (craigc_86 CC-BY-NC 4.0 (Int))](https://biocache.ala.org.au/occurrences/0dccaf64-9aed-4b5e-bbc9-06a7ee3ae11e), Middle: [*Dacelo (Dacelo) novaeguineae* (Wildash \\| questagame.com CC-BY-NC 4.0 (Int))](https://biocache.ala.org.au/occurrences/3e26b79d-803c-4b0a-95b7-05a39dad4caf), Right: [*Dacelo (Dacelo) novaeguineae* (c_a_critter CC-BY-NC 4.0 (Int))](https://biocache.ala.org.au/occurrences/6028fd90-df9b-4d12-86f8-08f47f005e61)\n:::\n\n::: aside\nThe laughing kookaburra also has one of the most recognisable bird calls. [This video is an amazing example](https://www.youtube.com/watch?v=TqdRQxgtZtI).\n:::\n\nWe'll choose a region in New South Wales...\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define geographic region\ncustom_bbox <- tibble(ymin = -35, \n                      ymax = -32, \n                      xmin = 149, \n                      xmax = 152.1)\n```\n:::\n\n\n::: aside\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n:::\n\n...and download records from the ALA.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngalah_config(email = \"your-email-here\") # Registered ALA email\n\n# download occurrence records\nkookaburras <- galah_call() |>\n  identify(\"Dacelo novaeguineae\") |>\n  filter(year == 2023) |>\n  galah_apply_profile(ALA) |>\n  galah_geolocate(custom_bbox, type = \"bbox\") |>\n  atlas_occurrences()\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n::: aside\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n:::\n\nFor many of the later steps we'll need the coordinates formatted as a spatial object (i.e., `geometry`). So, let's convert our occurrence data to a spatial object (`sf`) defined by the longitude and latitude coordinates, and set the Coordinate Reference System (CRS) to EPSG:4326[^crs] (WGS84).\n\n[^crs]: ALA data is projected using [CRS EPSG:4326](https://epsg.io/4326) (the same one used by Google Earth).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# convert to sf\nkookaburras_sf <- kookaburras |>\n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\")) |>\n  st_set_crs(4326)\n```\n:::\n\n\n### Download environmental data\n\nTo help with our model prediction, we'll also download the [BioClim variables](https://www.worldclim.org/data/bioclim.html), a list of 19 biologically relevant environmental variables, for all of Australia as a raster.\n\n::: {.callout-note collapse=\"true\"}\n#### What's a raster?\n\nA **raster** is a spatial grid of cells, where each cell contains a value representing information such as temperature or elevation. This information is often visualised by mapping colours to values in the raster (see image below). The resolution of the raster depends on the size of cells within the grid, with smaller cells corresponding to higher resolution (just like how the resolution of a television screen is determined by the number of pixels).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nplot_raster <- function(r) {\n  plot(r, axes = FALSE, legend = FALSE)\n  plot(as.polygons(r, dissolve = FALSE, trunc = FALSE), add = TRUE)\n  text(r, digits = 2)\n}\n\n# Create a 4 x 4 matrix\nm <- matrix(1:16, ncol = 4, nrow = 4)\n# Convert the matrix into a raster\nr16 <- rast(m)\n\nplot_raster(r16)\n```\n\n::: {.cell-output-display}\n![The colour of the cell/pixel is determined by the value assigned to it](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n:::\n\n\n```{=html}\n<!--\nNote: This data exists in the Science & Decision Support folder on Microsoft Teams\n* ./Data/science/projects/sdm-workflows/data\n-->\n```\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download world climate data\nbioclim <- geodata::worldclim_country(\n    country = \"Australia\",\n    var = \"bio\",\n    res = 5,\n    path = here::here(\"folder-name\", \n                      \"subfolder-name\")\n  )\n```\n:::\n\n::: {.cell}\n\n:::\n\n\nTo narrow our BioClim data to only within the extent of our defined bounding box, we'll create an extent object `bbox_ext`, then crop our `bioclim` layers to within `bbox_ext` and project our cropped BioClim data to the same CRS as our kookaburra occurrence points.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the coordinates to our bounding box\nbbox_ext <- terra::ext(\n  c(custom_bbox[[\"xmin\"]], \n    custom_bbox[[\"xmax\"]], \n    custom_bbox[[\"ymin\"]], \n    custom_bbox[[\"ymax\"]]\n    ))\n\n# Crop our worldclim data to within our bounding box coordinates\naus <- bioclim |>\n  terra::crop(bbox_ext) |>\n  terra::project(crs(\"EPSG:4326\"))\n```\n:::\n\n\nTo make sure everything looks correct, let's plot one of the variables with `geom_spatraster()` from the [tidyterra package](https://dieghernan.github.io/tidyterra/)[^tidyterra].\n\n[^tidyterra]: tidyterra follows the Grammar of Graphics made popular in R by ggplot2 and allows rasters to be plotted using the same syntax. In contrast, the terra package requires users to plot using base R styling (using `plot()`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download NSW map, set CRS projection\nnsw <- ozmaps::ozmap_states |>\n  filter(NAME == \"New South Wales\") |>\n  st_transform(crs = st_crs(4326))\n\n# Map of Annual temperature + points\nfirst_map <- ggplot() +\n  geom_spatraster(data = aus,\n                  aes(fill = wc2.1_30s_bio_1)) +\n  geom_sf(data = kookaburras_sf,\n          colour = \"#312108\",\n          size = 2) +\n  scale_fill_whitebox_c(palette = \"muted\",\n                        na.value = NA) +\n  guides(fill = guide_colorbar(title = \"Annual Mean\\nTemperature\")) +\n  theme_void()\n\nfirst_map\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n## Prepare data\n\nNow that we have our occurrence data and environmental data, there are a few steps we'll complete to prepare our data for modelling.\n\n### Thinning\n\nThe first step is to remove data where many points are overlapping. The resolution of our prediction is dependent on the resolution of our environmental data. If each cell in our environmental data defines the average value of one square kilometre, even if we had kookaburra observations at a higher resolution (for example, every square *metre* of our defined area), we can only detect differences to the lowest resolution of our grid cells.\n\nSo, we can **thin** our data so that there is only one observation per cell of our raster[^rast]. This step reduces spatial bias and lowers the risk that autocorrelation affects final predictions of our model.\n\n[^rast]: It's also possible to thin data by distance rather than cell size using [`tidysdm::thin_by_dist()`](https://evolecolgroup.github.io/tidysdm/reference/thin_by_dist.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# thin\nset.seed(12345)\nkookaburras_thin <- tidysdm::thin_by_cell(kookaburras_sf, \n                                          raster = aus\n                                          )\n\n# number of observations\ntibble(\n  before = nrow(kookaburras_sf),\n  after = nrow(kookaburras_thin)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  before after\n   <int> <int>\n1   5624  1575\n```\n\n\n:::\n:::\n\n\n::: aside\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n:::\n\n\n### Pseudo-absences\n\nOur data from the ALA is presence-only data. So, the second step is to create **pseudo-absences** (also called background points) that represent the full extent of the area where kookaburras haven't been observed (yet) in our data. Importantly, these are not the same as *true* absences and this should be taken into account when interpreting results[^trueabs].\n\n[^trueabs]: A true absence has quite a different meaning than a pseudo-absence to a species distribution model. The main difference is in the value a known absence provides compared to a simulated one for our interpretation of the results.<br><br>A *true* absence is a point where, at a specific time, an organism was not found there. Alternatively, a pseudo-absence is a point that *acts* like we haven't found an animal there, but we don't actually have data for that location! The model, however, doesn't *know* if a point represents a true absence or a psuedo-absence. It only knows the information it is given and will interpret that information using the parameters it is provided (in this way, models are a reflection of the real-world, but never a substitute).<br><br>Collecting *true* absence data is difficult, typically requiring expert knowledge, surveys with stricter methodologies, and repeated measures of the same areas over time. Pseudo-absences are much easier to collect---you simply simulate them on a computer---but they are less informative. Keep this trade-off in mind as you interpret your model's results.\n\nLet's add 3 times the number of presences to fill our grid, making sure they aren't closer than 5 km to another point like our occurrence points.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkookaburras_pseudoabs <- tidysdm::sample_pseudoabs(\n  kookaburras_thin,\n  n = 3 * nrow(kookaburras_thin),\n  raster = aus,\n  method = c(\"dist_min\", km2m(5))\n)\n```\n:::\n\n\n::: aside\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n:::\n\n### Extract environmental values\n\nNow that we have our presence and pseudo-absence points, the third step is to extract the environmental data for each point location in `aus` and bind the resulting values to our points data in `kookaburras_psuedoabs`. The result is a `tibble` with our points, their class, and the specific values of all 19 BioClim variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkookaburras_bioclim <- kookaburras_pseudoabs |> \n  bind_cols(\n    terra::extract(aus, \n                   kookaburras_pseudoabs, \n                   ID = FALSE)\n    )\nkookaburras_bioclim\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6300 features and 20 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 149.0042 ymin: -34.99952 xmax: 152.0958 ymax: -32.00211\nGeodetic CRS:  WGS 84\n# A tibble: 6,300 × 21\n   class                geometry wc2.1_30s_bio_1 wc2.1_30s_bio_2\n * <fct>             <POINT [°]>           <dbl>           <dbl>\n 1 presence (151.1115 -33.66282)            16.6            9.32\n 2 presence (151.1556 -33.68888)            16.7            9.15\n 3 presence (149.7309 -34.75422)            13.4           12.8 \n 4 presence (150.4131 -33.72526)            13.2            9.78\n 5 presence (151.1531 -33.82185)            17.8            9.29\n 6 presence  (150.6711 -34.0971)            16.7           12.0 \n 7 presence (151.0117 -33.64909)            16.6           10.5 \n 8 presence (150.2013 -33.38858)            11.2            9.94\n 9 presence (150.4419 -34.62589)            12.9           10.1 \n10 presence  (150.1324 -33.3652)            11.2           10.1 \n# ℹ 6,290 more rows\n# ℹ 17 more variables: wc2.1_30s_bio_3 <dbl>, wc2.1_30s_bio_4 <dbl>,\n#   wc2.1_30s_bio_5 <dbl>, wc2.1_30s_bio_6 <dbl>, wc2.1_30s_bio_7 <dbl>,\n#   wc2.1_30s_bio_8 <dbl>, wc2.1_30s_bio_9 <dbl>, wc2.1_30s_bio_10 <dbl>,\n#   wc2.1_30s_bio_11 <dbl>, wc2.1_30s_bio_12 <dbl>, wc2.1_30s_bio_13 <dbl>,\n#   wc2.1_30s_bio_14 <dbl>, wc2.1_30s_bio_15 <dbl>, wc2.1_30s_bio_16 <dbl>,\n#   wc2.1_30s_bio_17 <dbl>, wc2.1_30s_bio_18 <dbl>, wc2.1_30s_bio_19 <dbl>\n```\n\n\n:::\n:::\n\n\n### Select predictor variables\n\nThe fourth and final step is to choose predictor variables for our model. These are variables we think explain variation in our outcome (i.e., the probability a kookaburra could live in a given location). When choosing predictor variables, it is good practice to use theory and previous research to inform what variables you choose as predictors[^scale].\n\n[^scale]: Keep in mind that the strength of variables depends on the scale of your prediction. If you wish to make predictions at a broad-scale, variables like temperature and rainfall will likely be strong predictors, whereas if you wish to make predictions at a fine-scale, variables like food scarcity and competition might be stronger predictors for your outcome.\n\n:::{.callout-note collapse=\"true\"}\n\n#### Choosing variables and avoiding multicollinearity\n\nIn species distribution models, *multicollinearity*---high correlation between several independent variables in a model---can have unintended effects that bias predictions[^models]. Data science tools can also help refine your predictor variable choices, too, including [some functions in tidysdm](https://evolecolgroup.github.io/tidysdm/articles/a0_tidysdm_overview.html#thinning-step) that we used below.\n\n[^models]: A model can only use the information it is provided to make inferences about the world. If multiple variables in a model correlate, the model can place too much weight on those values to determine the outcome! The model isn't aware of the many other environmental variables that affect the real world outcome.\n\nA good start is to choose variables that differentiate between presences and pseudo-absences, which in the plot below are variables that have less overlap between red and blue distributions. To help choose variables with the highest non-overlapping distribution, we can decide on a percentage cut-off of 55% non-overlap, leaving us with the top 3 variables in the table below.\n\n:::{.panel-tabset .nav-pills style=\"margin-bottom:15px;\"}\n\n## Plot\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nkookaburras_bioclim |>\n  rename_with(\n    ~ str_remove_all(.x, \"wc2.1_30s_\"), \n    starts_with(\"wc2.1_30s_\")) |>\n  plot_pres_vs_bg(class)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## Table\n\n<style>\n.output-scroll {\n  max-height: 420px;\n  overflow-y: scroll;\n  margin-bottom: 20px;\n}\n</style>\n\n\n::: {.cell class='output-scroll'}\n\n```{.r .cell-code  code-fold=\"true\"}\noverlap <- kookaburras_bioclim |>\n  dist_pres_vs_bg(class) |>\n  enframe(\"bioclim\", \"percent_non_overlap\") |>\n  arrange(desc(percent_non_overlap))\n\noverlap |> gt::gt()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"pijvpfvvlz\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#pijvpfvvlz table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#pijvpfvvlz thead, #pijvpfvvlz tbody, #pijvpfvvlz tfoot, #pijvpfvvlz tr, #pijvpfvvlz td, #pijvpfvvlz th {\n  border-style: none;\n}\n\n#pijvpfvvlz p {\n  margin: 0;\n  padding: 0;\n}\n\n#pijvpfvvlz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#pijvpfvvlz .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pijvpfvvlz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pijvpfvvlz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pijvpfvvlz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pijvpfvvlz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pijvpfvvlz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pijvpfvvlz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pijvpfvvlz .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#pijvpfvvlz .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#pijvpfvvlz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pijvpfvvlz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pijvpfvvlz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pijvpfvvlz .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pijvpfvvlz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pijvpfvvlz .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#pijvpfvvlz .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#pijvpfvvlz .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#pijvpfvvlz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pijvpfvvlz .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#pijvpfvvlz .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pijvpfvvlz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pijvpfvvlz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pijvpfvvlz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pijvpfvvlz .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pijvpfvvlz .gt_left {\n  text-align: left;\n}\n\n#pijvpfvvlz .gt_center {\n  text-align: center;\n}\n\n#pijvpfvvlz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pijvpfvvlz .gt_font_normal {\n  font-weight: normal;\n}\n\n#pijvpfvvlz .gt_font_bold {\n  font-weight: bold;\n}\n\n#pijvpfvvlz .gt_font_italic {\n  font-style: italic;\n}\n\n#pijvpfvvlz .gt_super {\n  font-size: 65%;\n}\n\n#pijvpfvvlz .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#pijvpfvvlz .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#pijvpfvvlz .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#pijvpfvvlz .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#pijvpfvvlz .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#pijvpfvvlz .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#pijvpfvvlz .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"bioclim\">bioclim</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"percent_non_overlap\">percent_non_overlap</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_12</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.5638973</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_4</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.5600276</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_16</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.5534120</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_11</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.5394637</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_6</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.5210402</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_7</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.5113068</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_13</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4997009</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_9</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4827577</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_18</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4820482</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_1</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4599437</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_2</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4581933</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_17</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4464991</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_19</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4221545</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_15</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4202146</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_14</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.4099419</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_8</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.3411940</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_10</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.3182850</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_5</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.2343475</td></tr>\n    <tr><td headers=\"bioclim\" class=\"gt_row gt_left\">wc2.1_30s_bio_3</td>\n<td headers=\"percent_non_overlap\" class=\"gt_row gt_right\">0.1002332</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n:::\n\nNow we can use pair plots to view the relationship between each pair of variables. Variables `bio_12` and `bio_16` are very highly correlated (94%). To avoid multicollinearity in our model, we'll include only `bio_12` (annual precipitation) and `bio_4` (temperature seasonality).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\naus |>\n  select(wc2.1_30s_bio_12, \n         wc2.1_30s_bio_4, \n         wc2.1_30s_bio_16) |>\n  terra::pairs()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n:::\n\nHere, we selected two BioClim variables that we thought were reasonable environmental predictors (using mainly data science techniques):\n\n-   **BIO4**: Temperature Seasonality[^measure]\n-   **BIO12**: Annual Precipitation\n\n[^measure]: Measured as the standard deviation of the mean monthly temperature\n\nWe'll filter our point data and BioClim raster data to only include our two variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# predictor variable names\nvars <- c(\"wc2.1_30s_bio_4\", \"wc2.1_30s_bio_12\")\n\n# filter point data columns\nkookaburras_bioclim_filtered <- \n  kookaburras_bioclim |> \n  select(all_of(c(vars, \"class\")))\n\nkookaburras_bioclim_filtered |> head(5L)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 5 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 149.7309 ymin: -34.75422 xmax: 151.1556 ymax: -33.66282\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 4\n  wc2.1_30s_bio_4 wc2.1_30s_bio_12 class                geometry\n            <dbl>            <dbl> <fct>             <POINT [°]>\n1            391.             1204 presence (151.1115 -33.66282)\n2            390.             1275 presence (151.1556 -33.68888)\n3            504.              673 presence (149.7309 -34.75422)\n4            424.             1273 presence (150.4131 -33.72526)\n5            393.             1164 presence (151.1531 -33.82185)\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# filter bioclim data columns\naus_filtered <- aus[[vars]]\naus_filtered\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclass       : SpatRaster \ndimensions  : 360, 372, 2  (nrow, ncol, nlyr)\nresolution  : 0.008333333, 0.008333333  (x, y)\nextent      : 149, 152.1, -35, -32  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nnames       : wc2.1_30s_bio_4, wc2.1_30s_bio_12 \nmin values  :        306.3223,              620 \nmax values  :        582.4574,             1657 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbioclim4 <- ggplot() +\n  geom_spatraster(data = aus_filtered,\n                  aes(fill = wc2.1_30s_bio_4)) +\n  geom_rect(data = custom_bbox,\n            mapping = aes(xmin = xmin, \n                          ymin = ymin, \n                          xmax = xmax, \n                          ymax = ymax),\n            colour = \"grey50\",\n            fill = NA) +  \n  scale_fill_whitebox_c(palette = \"muted\",\n                        na.value = NA) +\n  guides(fill = guide_colorbar(title = \"Annual Range in\\nTemperature\\n(°C)\")) +\n  theme_void()\n\nbioclim12 <- ggplot() +\n  geom_spatraster(data = aus_filtered,\n                  aes(fill = wc2.1_30s_bio_12)) +\n  geom_rect(data = custom_bbox,\n            mapping = aes(xmin = xmin, \n                          ymin = ymin, \n                          xmax = xmax, \n                          ymax = ymax),\n            colour = \"grey50\",\n            fill = NA) +  \n  scale_fill_whitebox_c(palette = \"deep\",\n                        na.value = NA) +\n  guides(fill = guide_colorbar(title = \"Precipitation (mm)\")) +\n  theme_void()\n```\n:::\n\n::: {.cell .fig-column-body-outset layout-nrow=\"1\" layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![BioClim 4: Temperature Seasonality](index_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=672}\n:::\n\n::: {.cell-output-display}\n![BioClim 12: Annual Precipitation](index_files/figure-html/unnamed-chunk-27-2.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Fit model\n\nTidymodels is designed to build a model workflow, train the model's performance, then test the model's ability to predict data accurately. This workflow might be slightly different to what many research scientists are used to.\n\nIn machine learning models, data is like a limited resource that we must divide using a \"data budget\" for two main purposes: training a reasonable model, and testing the final model.\n\n### Split data\n\nThe first step to allocating your \"data budget\" is splitting your data. We can use `initial_split()` to allocate a reasonable \"data budget\" into these categories (typically a 75-25% split).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set training and testing data\nset.seed(100)\n\nkookaburras_split <- \n  kookaburras_bioclim_filtered |>\n  initial_split()\nkookaburras_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<4725/1575/6300>\n```\n\n\n:::\n:::\n\n\nNow we can save these data as separate data objects for `training()` and `testing()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkookaburras_train <- training(kookaburras_split)\nkookaburras_test <- testing(kookaburras_split)\n```\n:::\n\n\nWe are left with two dataframes with identical columns but different points.\n\n:::{.panel-tabset .nav-pills}\n\n## Train\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkookaburras_train |> head(5L)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 5 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 149.0125 ymin: -34.21327 xmax: 150.894 ymax: -32.3875\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 4\n  wc2.1_30s_bio_4 wc2.1_30s_bio_12 class                 geometry\n            <dbl>            <dbl> <fct>              <POINT [°]>\n1            498.              648 pseudoabs  (150.4792 -32.3875)\n2            374.             1442 presence   (150.894 -34.21327)\n3            561.              693 pseudoabs  (149.0125 -32.7875)\n4            486.              835 pseudoabs (150.1625 -32.72917)\n5            435.              890 pseudoabs  (150.7542 -33.1125)\n```\n\n\n:::\n:::\n\n\n## Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkookaburras_test |> head(5L)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 5 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 149.6909 ymin: -33.82185 xmax: 151.6858 ymax: -32.9229\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 4\n  wc2.1_30s_bio_4 wc2.1_30s_bio_12 class                geometry\n            <dbl>            <dbl> <fct>             <POINT [°]>\n1            393.             1164 presence (151.1531 -33.82185)\n2            461.             1085 presence (150.2013 -33.38858)\n3            513.              802 presence (149.6909 -33.14061)\n4            408.             1144 presence  (151.6858 -32.9229)\n5            463.             1073 presence (150.1981 -33.37893)\n```\n\n\n:::\n:::\n\n\n:::\n\n### Resampling\n\nNow let's resample our training data so we can use it to optimise and evaluate our model. One way to resample is using *cross-validation*, a well-established method of resampling that randomly assigns points to analysis and assessment groups. These randomly resampled and split data sets are known as *folds*. We can use the [spatialsample package](https://spatialsample.tidymodels.org/) to create 5 v-folds with `spatial_block_cv()`, a function for resampling spatial data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(100)\nkookaburras_cv <- spatial_block_cv(kookaburras_train, v = 5)\n```\n:::\n\n\n`spatial_block_cv()` uses a type of resampling called *block cross-validation*, which creates a grid of \"blocks\" and attempts to maintain these blocked groups when resampling data points. Block cross-validation is important because spatial data is not completely random; data from neighbouring locations probably relate in some way (they aren't completely random), and block cross-validation attempts to preserve this spatial relationship. The plots below demonstrate the general process. The plot on the left shows the blocks, the animation on the right shows the resulting 5 folds.\n\n:::{.column-page layout-ncol=\"2\"}\n\n:::{}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n\n:::{}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/splits-gif-.gif){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n:::\n\n\n### Define our model\n\nNext let's make our model's \"recipe\". This is the tidymodels term for any pre-processing steps that happen to our data before adding them to a model. A recipe includes our model formula, and any transformations or standardisations we might wish to do[^trans].\n\n[^trans]: For example, log transformation, centring scales, setting dummy variables\n\nIn our case, let's define that our model's outcome variable is the `class` of presence or absence. We'll then add our predictor variables to our model, with the formula `class ~ .`, equivalent to `class ~ bio4 + bio12`.\n\n\n::: {.cell .column-page-inset-right}\n\n```{.r .cell-code}\nkookaburras_recipe <- recipe(\n  kookaburras_train, \n  formula = class ~ .\n  )\nkookaburras_recipe\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:   1\npredictor: 2\ncoords:    2\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\nNow we can set our workflow, which merges our formula, any data pre-processing, and specifies which models we'll use. One of the strengths of using tidymodels is that we can run several different types of models in a single [`workflow_set()`](https://workflowsets.tidymodels.org/index.html) to train and optimise them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkookaburras_models <-\n  # create the workflow_set\n  workflow_set(\n    preproc = list(default = kookaburras_recipe),\n    models = list(\n      glm = sdm_spec_glm(),        # the standard glm specs\n      rf = sdm_spec_rf(),          # rf specs with tuning\n      gbm = sdm_spec_boost_tree(), # boosted tree model (gbm) specs with tuning\n      maxent = sdm_spec_maxent()   # maxent specs with tuning\n    ),\n    cross = TRUE # make all combinations of preproc and models\n  ) |>\n  # tweak controls to store information needed later to create the ensemble\n  option_add(control = control_ensemble_grid())\n\nkookaburras_models\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A workflow set/tibble: 4 × 4\n  wflow_id       info             option    result    \n  <chr>          <list>           <list>    <list>    \n1 default_glm    <tibble [1 × 4]> <opts[1]> <list [0]>\n2 default_rf     <tibble [1 × 4]> <opts[1]> <list [0]>\n3 default_gbm    <tibble [1 × 4]> <opts[1]> <list [0]>\n4 default_maxent <tibble [1 × 4]> <opts[1]> <list [0]>\n```\n\n\n:::\n:::\n\n\n### Fit our model\n\nNext we will determine what parameters optimise our model's performance by **tuning** our model. Tuning uses trial-and-error to figure out which type of model under what hyperparameters makes reasonable predictions.\n\nLet's tune our models using our resampled folds (`kookaburras_cv`).\n\n::: {.callout-note collapse=\"true\"}\n## How does tuning work?\n\nTuning is the process of simulating many different ways to fit lines made by our models to our training data. The number of curves in a model's line of best fit increases as a model becomes more complex, determined by its degrees of freedom. By using different functions to set reasonable weighting parameters that penalize a model when lines curve too much, tuning optimises the model's performance by finding the balance between fitting our current training data and predicting new values correctly. For more information and a visual of this, check out the [tunes package Getting Started vignette](https://tune.tidymodels.org/articles/tune.html).\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2345678) # for reproducability\n\nkookaburras_models_tune <-\n  kookaburras_models |>\n  workflow_map(\"tune_grid\",\n    resamples = kookaburras_cv, \n    grid = 6,                   # increase for more iterations\n    metrics = sdm_metric_set(),\n    verbose = TRUE,\n    control = stacks::control_stack_grid()\n  )\n\nkookaburras_models_tune\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A workflow set/tibble: 4 × 4\n  wflow_id       info             option    result   \n  <chr>          <list>           <list>    <list>   \n1 default_glm    <tibble [1 × 4]> <opts[4]> <rsmp[+]>\n2 default_rf     <tibble [1 × 4]> <opts[4]> <tune[+]>\n3 default_gbm    <tibble [1 × 4]> <opts[4]> <tune[+]>\n4 default_maxent <tibble [1 × 4]> <opts[4]> <tune[+]>\n```\n\n\n:::\n\n```{.r .cell-code}\nbeepr::beep(2)\n```\n:::\n\n\nWe can use `autoplot()` to visualise which models performed best by a set of common performance metrics for species distribution models. Models with higher values and smaller confidence intervals performed better.\n\n\n::: {.cell .fig-column-page layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(kookaburras_models_tune)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-37-1.png){fig-align='center' width=768 style=margin-left:auto;margin-right:auto;}\n:::\n:::\n\n\n\nWe can also collect each model's metrics and rank the models by performance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# see metrics\ncollect_metrics(kookaburras_models_tune) # <1>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 45 × 9\n   wflow_id    .config      preproc model .metric .estimator  mean     n std_err\n   <chr>       <chr>        <chr>   <chr> <chr>   <chr>      <dbl> <int>   <dbl>\n 1 default_glm Preprocesso… spatia… logi… boyce_… binary     0.890     5  0.0374\n 2 default_glm Preprocesso… spatia… logi… roc_auc binary     0.861     5  0.0327\n 3 default_glm Preprocesso… spatia… logi… tss_max binary     0.633     5  0.0617\n 4 default_rf  Preprocesso… spatia… rand… boyce_… binary     0.753     5  0.0907\n 5 default_rf  Preprocesso… spatia… rand… roc_auc binary     0.792     5  0.0400\n 6 default_rf  Preprocesso… spatia… rand… tss_max binary     0.493     5  0.0681\n 7 default_rf  Preprocesso… spatia… rand… boyce_… binary     0.761     5  0.0841\n 8 default_rf  Preprocesso… spatia… rand… roc_auc binary     0.799     5  0.0394\n 9 default_rf  Preprocesso… spatia… rand… tss_max binary     0.505     5  0.0670\n10 default_gbm Preprocesso… spatia… boos… boyce_… binary     0.745     5  0.107 \n# ℹ 35 more rows\n```\n\n\n:::\n:::\n\n\n1.  As a general tidymodels tip, many columns with a `.` at the start of its column name can be retrieved with a `collect_` function (e.g., `collect_metrics()`, `collect_parameters()`).\n\nOur tuning results show that several types of models and parameters performed quite well. Rather than choosing only one model to use for predictions, it's possible to use several as a \"stacked ensemble model\"! The [stacks package](https://stacks.tidymodels.org/index.html) in tidymodels let's us blend predictions of a few good candidate models (based on whatever metric you choose) to make better overall estimates[^stacks].\n\n[^stacks]: To learn more about how putting together a stack works, check out [this helpful article on the stacks website](https://stacks.tidymodels.org/articles/basics.html#putting-together-a-stack).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stacks)\nset.seed(123456)\n\nkookaburras_stacked <- \n  stacks() |>                                # initialize the stack\n  add_candidates(kookaburras_models_tune) |> # add candidate members\n  blend_predictions() |>                     # determine how to combine their predictions\n  fit_members()                              # fit the candidates with nonzero stacking coefficients\n\nkookaburras_stacked\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  member                             type         weight\n  <chr>                              <chr>         <dbl>\n1 .pred_pseudoabs_default_maxent_1_1 maxent        2.25 \n2 .pred_pseudoabs_default_glm_1_1    logistic_reg  0.875\n```\n\n\n:::\n:::\n\n\nHere is a nice visual of how these two member models are weighted to inform our predictions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(kookaburras_stacked, type = \"weights\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-40-1.png){width=672}\n:::\n:::\n\n\n\n## Assess model\n\nOur model `kookaburras_stacked` is now ready, and we can use it to make predictions about our test data. We'll bind the predicted values to the true values of our test data...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkookaburras_test_predictions <-\n  kookaburras_test %>%\n  bind_cols(predict(kookaburras_stacked, ., \n                    type = \"prob\", \n                    save_pred = TRUE))\n```\n:::\n\n\n...which allows us to assess how good our model is at making correct predictions of the \"true\" classes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkookaburras_test_predictions |> \n  sdm_metric_set()(truth = class, .pred_presence)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  .metric    .estimator .estimate\n  <chr>      <chr>          <dbl>\n1 boyce_cont binary         0.968\n2 roc_auc    binary         0.848\n3 tss_max    binary         0.565\n```\n\n\n:::\n:::\n\n\nWe can also visualise how well the model has correctly predicted the class of each point by predicting `\"class\"` rather than `\"prob\"` and mapping correct vs incorrect predictions.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# predict class\nkookaburras_test_predictions_class <-\n  kookaburras_test %>%\n  bind_cols(predict(kookaburras_stacked, ., \n                    type = \"class\", \n                    save_pred = TRUE))\n\n# plot correct vs incorrect predictions\nkookaburras_test_predictions_class |>\n  mutate(correct = case_when(\n    class == .pred_class ~ \"Correct\",\n    TRUE ~ \"Incorrect\"\n  )) |>\n  ggplot() +\n  geom_sf(aes(geometry = geometry, colour = correct)) +\n  labs(color = NULL) +\n  scale_color_manual(values = c(\"darkred\", \"lightpink\")) + \n  geom_spatraster(data = aus,\n                  aes(fill = wc2.1_30s_bio_4),\n                  alpha = 0.1) +\n  scale_fill_whitebox_c(palette = \"muted\",\n                        na.value = NA) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## tidysdm wrapper functions\n\ntidysdm offers its own wrapper function [`simple_ensemble()`](https://evolecolgroup.github.io/tidysdm/reference/simple_ensemble.html) to run a stack model workflow and some [helpful ways](https://evolecolgroup.github.io/tidysdm/articles/a2_tidymodels_additions.html#exploring-models-with-dalex) to assess their performance.\n:::\n\n### Final prediction\n\nFinally, we can use our model to predict the habitat suitability of laughing kookaburras over our area. We'll predict an entire surface of values within our `aus_filtered` area using the incredible `predict_raster()` function from tidysdm (which saves us quite a few wrangling steps to work nicely with terra).\n\n\n::: {.cell .fig-column-page layout-align=\"center\" lightbox='{\"group\":\"final-plot\",\"description\":\"Predicted distribution of laughing kookaburras\"}'}\n\n```{.r .cell-code}\n# predict\nprediction_present <- predict_raster(kookaburras_stacked, \n                                     aus_filtered, \n                                     type = \"prob\")\n\n# map\nggplot() +\n  geom_spatraster(data = prediction_present, \n                  aes(fill = .pred_presence)) +\n  scale_fill_whitebox_c(palette = \"purple\",\n                        na.value = NA) +\n  guides(\n    fill = guide_colorbar(title=\"Relative\\nHabitat\\nSuitability\")\n    ) +\n\n  # plot presences used in the model\n  geom_sf(data = kookaburras_sf,\n          alpha = 0.3) +\n  labs(title=\"Predicted distribution of laughing kookaburras\") +\n  pilot::theme_pilot(grid=\"hv\") +\n  theme(\n    legend.text = element_text(hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-44-1.png){fig-align='center' width=864 style=margin-left:auto;margin-right:auto;}\n:::\n:::\n\n\nAnd there we have our predictions of our species distribution model!\n\n## Final thoughts\n\nWe hope this article has made the steps of species distribution modelling and interpretation clearer. Species distribution models remain one of the most powerful statistical tools for making inferences about species and their habitat range. tidymodels, tidysdm, and tidyterra offer a useful toolset for running these models in R.\n\nAlthough our model performed decently under several model performance metrics, no model is perfect. For example, you can see that many of the values towards the centre of Australia have low relative habitat suitability despite quite a few kookaburra occurrences. This is a limitation likely caused by our data and our choice of predictor variables. Testing different subsets of predictors and trying environmental layers at different levels of spatial resolution will help to improve the performance of the model. Another option (if collecting more data is not feasible) is to explore other datasets that could be aggregated to enhance the quality of training data.\n\nOur model above is quite minimalist (for simplicity). If you'd like an example list of variables used in more performant models, check out [this paper](https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giae002/7619364?login=true#:~:text=prior%20to%20modeling.-,Table%C2%A01%3A,-Summary%20of%20the).\n\nTo learn more on ALA Labs, check out our posts on [spatial bias](https://labs.ala.org.au/posts/2022-07-22_sample-bias/) and [mapping multiple overlapping species distributions](https://labs.ala.org.au/posts/2024-01-25_hex_point_maps/).\n\n<details>\n\n<summary style=\"color: #E06E53;\">\n\nExpand for session info\n\n</summary>\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31 ucrt)\n os       Windows 10 x64 (build 19045)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2024-05-02\n pandoc   3.1.1 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package       * version date (UTC) lib source\n broom         * 1.0.5   2023-06-09 [1] CRAN (R 4.3.1)\n dials         * 1.2.0   2023-04-03 [1] CRAN (R 4.3.2)\n dplyr         * 1.1.4   2023-11-17 [1] CRAN (R 4.3.2)\n forcats       * 1.0.0   2023-01-29 [1] CRAN (R 4.3.2)\n galah         * 2.0.2   2024-04-12 [1] CRAN (R 4.3.3)\n ggplot2       * 3.4.4   2023-10-12 [1] CRAN (R 4.3.1)\n glmnet        * 4.1-8   2023-08-22 [1] CRAN (R 4.3.1)\n here          * 1.0.1   2020-12-13 [1] CRAN (R 4.3.2)\n htmltools     * 0.5.7   2023-11-03 [1] CRAN (R 4.3.2)\n infer         * 1.0.5   2023-09-06 [1] CRAN (R 4.3.1)\n lubridate     * 1.9.3   2023-09-27 [1] CRAN (R 4.3.2)\n Matrix        * 1.6-4   2023-11-30 [1] CRAN (R 4.3.2)\n maxnet        * 0.1.4   2021-07-09 [1] CRAN (R 4.3.2)\n modeldata     * 1.2.0   2023-08-09 [1] CRAN (R 4.3.1)\n ozmaps        * 0.4.5   2021-08-03 [1] CRAN (R 4.3.2)\n parsnip       * 1.1.1   2023-08-17 [1] CRAN (R 4.3.1)\n purrr         * 1.0.2   2023-08-10 [1] CRAN (R 4.3.2)\n ranger        * 0.16.0  2023-11-12 [1] CRAN (R 4.3.2)\n readr         * 2.1.5   2024-01-10 [1] CRAN (R 4.3.3)\n recipes       * 1.0.8   2023-08-25 [1] CRAN (R 4.3.1)\n rsample       * 1.2.0   2023-08-23 [1] CRAN (R 4.3.1)\n scales        * 1.3.0   2023-11-28 [1] CRAN (R 4.3.2)\n sessioninfo   * 1.2.2   2021-12-06 [1] CRAN (R 4.3.2)\n sf            * 1.0-16  2024-03-24 [1] CRAN (R 4.3.3)\n spatialsample * 0.5.1   2023-11-08 [1] CRAN (R 4.3.2)\n stacks        * 1.0.3   2023-11-06 [1] CRAN (R 4.3.3)\n stringr       * 1.5.1   2023-11-14 [1] CRAN (R 4.3.2)\n terra         * 1.7-55  2023-10-13 [1] CRAN (R 4.3.1)\n tibble        * 3.2.1   2023-03-20 [1] CRAN (R 4.3.2)\n tidymodels    * 1.1.1   2023-08-24 [1] CRAN (R 4.3.1)\n tidyr         * 1.3.1   2024-01-24 [1] CRAN (R 4.3.3)\n tidysdm       * 0.9.2   2023-11-13 [1] CRAN (R 4.3.2)\n tidyterra     * 0.5.0   2023-11-21 [1] CRAN (R 4.3.2)\n tidyverse     * 2.0.0   2023-02-22 [1] CRAN (R 4.3.2)\n tune          * 1.1.2   2023-08-23 [1] CRAN (R 4.3.1)\n workflows     * 1.1.3   2023-02-22 [1] CRAN (R 4.3.2)\n workflowsets  * 1.0.1   2023-04-06 [1] CRAN (R 4.3.2)\n xgboost       * 1.7.6.1 2023-12-06 [1] CRAN (R 4.3.1)\n yardstick     * 1.2.0   2023-04-21 [1] CRAN (R 4.3.2)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.3.2/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n</details>\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}